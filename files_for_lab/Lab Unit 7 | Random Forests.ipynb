{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad46e21",
   "metadata": {},
   "source": [
    "# Lab Unit 7 | Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3eccdc",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0ac6d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard libraries for data analysis:\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, skew, shapiro\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import re #regex\n",
    "\n",
    "# sklearn modules for data preprocessing:\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#sklearn modules for Model Selection:\n",
    "from sklearn import svm, tree, linear_model, neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "#Standard libraries for data visualization:\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox \n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib \n",
    "%matplotlib inline\n",
    "color = sns.color_palette()\n",
    "import matplotlib.ticker as mtick\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a0094",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0422b96",
   "metadata": {},
   "source": [
    "## X/Y Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "07fe9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_y(df):\n",
    "    X = df.drop(['TARGET_B','TARGET_D'], axis = 1)\n",
    "    y = df['TARGET_B']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c5c22e",
   "metadata": {},
   "source": [
    "## Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2b532488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X,y,n):\n",
    "      \n",
    "    # Split into training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=n)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d665e94",
   "metadata": {},
   "source": [
    "## Categorical vs Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8c1a7c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xnum_Xcat(X_train, X_test):\n",
    "    \n",
    "    #split into numerical and categorical\n",
    "    X_train_cat = X_train.select_dtypes(include = object)\n",
    "    X_train_num =X_train.select_dtypes(include = np.number)\n",
    "\n",
    "    X_test_cat = X_test.select_dtypes(include = object)\n",
    "    X_test_num =X_test.select_dtypes(include = np.number)\n",
    "    \n",
    "    display(X_train_cat.shape)\n",
    "    display(X_train_num.shape)\n",
    "    display(X_test_cat.shape)\n",
    "    display(X_test_num.shape)\n",
    "    \n",
    "    return X_train_cat, X_train_num, X_test_cat, X_test_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b480ac",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7e28c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_encoding(X_num,X_cat):\n",
    "    \n",
    "\n",
    "    # MinMaxScale numerical features to ensure that all variables are on the same scale\n",
    "    scaler = MinMaxScaler().fit(X_num)\n",
    "\n",
    "    X_num_scaled = scaler.transform(X_num)\n",
    "    X_num_scaled = pd.DataFrame(X_num_scaled)\n",
    "    X_num_scaled.columns = X_num.columns\n",
    "    X_num_scaled.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Encode to ensure that all variables are on the same scale\n",
    "\n",
    "    encoder = OneHotEncoder(drop='first').fit(X_cat)\n",
    "    \n",
    "    cols = encoder.get_feature_names_out(input_features=X_cat.columns)\n",
    "    X_cat_encoded = pd.DataFrame(encoder.transform(X_cat).toarray(),columns=cols)\n",
    "    X_cat_encoded.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n",
    "    \n",
    "    return X_num_scaled, X_cat_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "993a8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(df1,df2):\n",
    "    \n",
    "    # Combine two dataframes, one next to other\n",
    "    X_normalized = pd.concat([df1,df2], axis = 1)\n",
    "    \n",
    "    return X_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8d60ce",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f218f050",
   "metadata": {},
   "source": [
    "#### Variance Threshold Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d2bba6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to look at VarianceThresholds we need all the variable to be on the same scale\n",
    "# Variance Threshold Feature Selection only works with numerical data, encoding categorical data is required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "201cdcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def variance_threshold(var_threshold,df):\n",
    "    \n",
    "    # use the estimator with a low threshold (minimum value of variance we want in out dataset)\n",
    "    selection = VarianceThreshold(threshold=(var_threshold))\n",
    "\n",
    "    # Fit\n",
    "    selection = selection.fit(df)\n",
    "    \n",
    "    # Subset the DataFrame\n",
    "    data_variance = selection.transform(df)\n",
    "    data_variance = pd.DataFrame(data_variance)\n",
    "    \n",
    "    # Get list of features removed\n",
    "    var_list = list(selection.get_support())\n",
    "    \n",
    "    drop_columns = [col[0] for col in zip(df.columns, var_list) if col[1] == False]\n",
    "    \n",
    "    return drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "17380f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_features(df, original_df, drop_columns):\n",
    "    \n",
    "    df_cleaned = df.drop(drop_columns, axis = 1)\n",
    "    \n",
    "    print('Original set: ', original_df.shape)\n",
    "    print('New set: ', df_cleaned.shape)\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf719c98",
   "metadata": {},
   "source": [
    "#### Kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f2268cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KBest(X, target, k):\n",
    "    \n",
    "    K_best = SelectKBest(chi2, k=k).fit_transform(X, target)\n",
    "    \n",
    "    \n",
    "    # feature extraction\n",
    "    model = SelectKBest(chi2, k=k).fit(X, target)\n",
    "    df = pd.DataFrame(data = model.scores_, columns=['score'])\n",
    "    df['column_name']= X.columns\n",
    "\n",
    "    # summarize selected features\n",
    "    display(df.sort_values(by = ['score'],ascending = False).head(k))\n",
    "    \n",
    "    # Add columns to drop to a list\n",
    "    cols = df.sort_values(by = ['score'],ascending = False).head(k)['column_name']\n",
    "    drop_columns = list(cols)\n",
    "    \n",
    "    \n",
    "    return drop_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f4fdff",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0a8ff271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "\n",
    "def RFE_regression(model,n,X,y):\n",
    "    \n",
    "    # define the method\n",
    "    method = model(max_iter = 500)\n",
    "    rfe = RFE(method, n_features_to_select=n, verbose=False)\n",
    "    \n",
    "    # fit the model\n",
    "    rfe.fit(X, y)\n",
    "    \n",
    "    # Summarize features\n",
    "    df = pd.DataFrame(data = rfe.ranking_, columns=['Rank'])\n",
    "    df['Column_name'] = pd.DataFrame(X).columns\n",
    "    df = df[df['Rank']==1]\n",
    "    \n",
    "    # Create a list with columns to keep\n",
    "    columns_lst = list(df['Column_name'].values)\n",
    "    \n",
    "    \n",
    "    return columns_lst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ba181f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_features(X, original_df, columns_lst):\n",
    "    # Show only most important features\n",
    "    df2 = X[[*columns_lst]]\n",
    "    \n",
    "    \n",
    "    print('Original set: ',original_df.shape) # to be adjust according to the project\n",
    "    print('RFE set: ',df2.shape)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4be5b",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2b22dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest(X_train,y_train,X_test,y_test):\n",
    "    # Init, fit, score\n",
    "    forest = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf =20)\n",
    "\n",
    "    _ = forest.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # Training Score\n",
    "    print(f\"Training Score: {forest.score(X_train, y_train)}\")\n",
    "\n",
    "    print(f\"Test Score: {forest.score(X_test, y_test)}\")\n",
    "\n",
    "    \n",
    "    # Make predictions / confusion_matrix\n",
    "    y_pred = forest.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(\"precision: \",precision_score(y_test,y_pred))\n",
    "    print(\"recall: \",recall_score(y_test,y_pred))\n",
    "    print(\"f1: \",f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d8b793",
   "metadata": {},
   "source": [
    "# LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895e792",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef35f5a6",
   "metadata": {},
   "source": [
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "64fbc2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = pd.read_csv('categorical.csv')\n",
    "numerical = pd.read_csv('numerical.csv')\n",
    "target = pd.read_csv('target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1c89c357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95412, 339)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([numerical, categorical, target], axis = 1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53883cd",
   "metadata": {},
   "source": [
    "## X/Y Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cfd86ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = x_y(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169dddec",
   "metadata": {},
   "source": [
    "## Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ddcb0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test(X,y,0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98258ae2",
   "metadata": {},
   "source": [
    "## Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "305f6d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    90569\n",
       "1     4843\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TARGET_B'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "841936ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full df with training data\n",
    "train_set = pd.concat([X_train,y_train], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53e887",
   "metadata": {},
   "source": [
    "#### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f9475ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_donate = train_set[train_set['TARGET_B']==0]\n",
    "yes_donate = train_set[train_set['TARGET_B']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "58aa1a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67942, 338)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(67942, 338)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "yes_donate_oversampled = resample(yes_donate, \n",
    "                                    replace=True,\n",
    "                                    n_samples = len(no_donate),\n",
    "                                    random_state=42)\n",
    "\n",
    "\n",
    "display(no_donate.shape)\n",
    "display(yes_donate_oversampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c90e7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a full df again\n",
    "oversampled_target = pd.concat([no_donate,yes_donate_oversampled], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a969cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrambled rows to avoid yes/no clusters\n",
    "oversampled_total = oversampled_target.sample(frac=1)\n",
    "\n",
    "# X/y split after upsampling\n",
    "X_train_oversampled = oversampled_total.drop(['TARGET_B'], axis = 1)\n",
    "\n",
    "y_train_oversampled =oversampled_total['TARGET_B']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670546a3",
   "metadata": {},
   "source": [
    "## Categorical vs Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "31ccc525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135884, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(135884, 330)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(23853, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(23853, 330)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_cat, X_train_num, X_test_cat, X_test_num = Xnum_Xcat(X_train_oversampled,X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1645bf60",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0fd7beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num_scaled, X_train_cat_scaled = scaling_encoding(X_train_num, X_train_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "958e6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_num_scaled, X_test_cat_scaled = scaling_encoding(X_test_num, X_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "962ae4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = concat_df(X_train_num_scaled, X_train_cat_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f4a2729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_normalized = concat_df(X_test_num_scaled, X_test_cat_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd2ce82",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab97662",
   "metadata": {},
   "source": [
    "#### Variance Threshold Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "883c13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = variance_threshold(0.02,X_train_normalized)\n",
    "#drop_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281c05b",
   "metadata": {},
   "source": [
    "Remove columns with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cbc25856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original set:  (71559, 337)\n",
      "New set:  (135884, 114)\n"
     ]
    }
   ],
   "source": [
    "X_train_normalized_cleaned = drop_features(X_train_normalized, X_train, drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0981aea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original set:  (23853, 337)\n",
      "New set:  (23853, 114)\n"
     ]
    }
   ],
   "source": [
    "X_test_normalized_cleaned = drop_features(X_test_normalized, X_test, drop_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba006f",
   "metadata": {},
   "source": [
    "#### KBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "32950b6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>column_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1294.551818</td>\n",
       "      <td>RFA_2F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>894.011855</td>\n",
       "      <td>RFA_2A_G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>607.801459</td>\n",
       "      <td>RFA_2A_E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>431.772841</td>\n",
       "      <td>LASTDATE_YR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>382.165575</td>\n",
       "      <td>RFA_2A_F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>187.213922</td>\n",
       "      <td>HVP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>181.808943</td>\n",
       "      <td>HVP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>134.741516</td>\n",
       "      <td>HVP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>129.231271</td>\n",
       "      <td>HVP6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>99.709859</td>\n",
       "      <td>HVP4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>94.597672</td>\n",
       "      <td>LASTDATE_MM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>89.069369</td>\n",
       "      <td>ODATEW_YR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>88.961495</td>\n",
       "      <td>ETH2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>88.431117</td>\n",
       "      <td>RP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>79.479769</td>\n",
       "      <td>STATE_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>65.903044</td>\n",
       "      <td>RP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>60.703197</td>\n",
       "      <td>HV1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>59.906078</td>\n",
       "      <td>HV2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>51.416417</td>\n",
       "      <td>DOMAIN_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>48.554140</td>\n",
       "      <td>STATE_GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>46.961901</td>\n",
       "      <td>HOMEOWNR_U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>45.879238</td>\n",
       "      <td>CARDPROM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>45.239627</td>\n",
       "      <td>HVP5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>40.837809</td>\n",
       "      <td>DOB_MM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40.239364</td>\n",
       "      <td>RP3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score  column_name\n",
       "77   1294.551818       RFA_2F\n",
       "106   894.011855     RFA_2A_G\n",
       "104   607.801459     RFA_2A_E\n",
       "87    431.772841  LASTDATE_YR\n",
       "105   382.165575     RFA_2A_F\n",
       "27    187.213922         HVP1\n",
       "28    181.808943         HVP2\n",
       "29    134.741516         HVP3\n",
       "32    129.231271         HVP6\n",
       "30     99.709859         HVP4\n",
       "88     94.597672  LASTDATE_MM\n",
       "82     89.069369    ODATEW_YR\n",
       "10     88.961495         ETH2\n",
       "37     88.431117          RP1\n",
       "93     79.479769     STATE_IN\n",
       "38     65.903044          RP2\n",
       "17     60.703197          HV1\n",
       "18     59.906078          HV2\n",
       "81     51.416417     DOMAIN_B\n",
       "91     48.554140     STATE_GA\n",
       "101    46.961901   HOMEOWNR_U\n",
       "74     45.879238     CARDPROM\n",
       "31     45.239627         HVP5\n",
       "84     40.837809       DOB_MM\n",
       "39     40.239364          RP3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drop_columns = KBest(X_train_normalized_cleaned,y_train_oversampled,25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1338fb01",
   "metadata": {},
   "source": [
    "Drop columns with the k lowest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d0d07898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original set:  (71559, 337)\n",
      "New set:  (135884, 89)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(135884, 89)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normalized_cleaned_2 = drop_features(X_train_normalized_cleaned, X_train, drop_columns)\n",
    "X_train_normalized_cleaned_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b45442b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original set:  (23853, 337)\n",
      "New set:  (23853, 89)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23853, 89)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_normalized_cleaned_2 = drop_features(X_test_normalized_cleaned, X_test, drop_columns)\n",
    "X_test_normalized_cleaned_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b26bc",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6a89efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_lst = RFE_regression(LogisticRegression,50,X_train_normalized_cleaned_2,y_train_oversampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "db5b71c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original set:  (71559, 337)\n",
      "RFE set:  (135884, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train_normalized_cleaned_RFE = keep_features(X_train_normalized_cleaned_2, X_train, columns_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a04eeed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original set:  (23853, 337)\n",
      "RFE set:  (23853, 50)\n"
     ]
    }
   ],
   "source": [
    "X_test_normalized_cleaned_RFE = keep_features(X_test_normalized_cleaned_2, X_test, columns_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9803ff8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f87b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3621957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fcc492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "475653e5",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8ed22215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.6240764181213387\n",
      "Test Score: 0.7137466985284869\n",
      "[[16490  6137]\n",
      " [  691   535]]\n",
      "precision:  0.08018585131894485\n",
      "recall:  0.4363784665579119\n",
      "f1:  0.13547733603443912\n"
     ]
    }
   ],
   "source": [
    "# Full dataset - all features\n",
    "\n",
    "forest(X_train_normalized,y_train_oversampled,X_test_normalized,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3390963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.6267919696211475\n",
      "Test Score: 0.611663103173605\n",
      "[[13885  8742]\n",
      " [  521   705]]\n",
      "precision:  0.07462686567164178\n",
      "recall:  0.5750407830342578\n",
      "f1:  0.13210906024547925\n"
     ]
    }
   ],
   "source": [
    "# Dataset after Variance Tr\n",
    "\n",
    "forest(X_train_normalized_cleaned,y_train_oversampled,X_test_normalized_cleaned,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "07796780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.6109107768390686\n",
      "Test Score: 0.6029011025866767\n",
      "[[13786  8841]\n",
      " [  631   595]]\n",
      "precision:  0.06305637982195846\n",
      "recall:  0.48531810766721045\n",
      "f1:  0.11161132995685612\n"
     ]
    }
   ],
   "source": [
    "# Dataset after Kbest\n",
    "\n",
    "forest(X_train_normalized_cleaned_2,y_train_oversampled,X_test_normalized_cleaned_2,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "79328e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.6050381207500515\n",
      "Test Score: 0.6028591791388924\n",
      "[[13800  8827]\n",
      " [  646   580]]\n",
      "precision:  0.061656213458063144\n",
      "recall:  0.4730831973898858\n",
      "f1:  0.10909432897582996\n"
     ]
    }
   ],
   "source": [
    "forest(X_train_normalized_cleaned_RFE,y_train_oversampled,X_test_normalized_cleaned_RFE,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e9ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
